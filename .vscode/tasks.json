{
    "version": "2.0.0",
    "tasks": [
        {
            "label": "Rasa: Dry Run (layers - preset)",
            "type": "shell",
            "command": "bash scripts/layer_rasa_projects.sh --dry-run=stdout ${input:layersPreset}",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": []
        },
        {
            "label": "Rasa: Dry Run (layers - custom)",
            "type": "shell",
            "command": "bash scripts/layer_rasa_projects.sh --dry-run=stdout ${input:layersCustom}",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": []
        },
        {
            "label": "Rasa: Train (layers - preset)",
            "type": "shell",
            "command": "./scripts/layer_rasa_projects.sh ${input:layersPreset}",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": []
        },
        {
            "label": "Rasa: Train (layers - custom)",
            "type": "shell",
            "command": "./scripts/layer_rasa_projects.sh ${input:layersCustom}",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": []
        },
        {
            "label": "Rasa: Shell (latest)",
            "type": "shell",
            "command": "rasa shell --model models --endpoints src/core/endpoints.yml",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": []
        },
        {
            "label": "Rasa: Run (latest)",
            "type": "shell",
            "command": "rasa run --enable-api --cors '*' --model models --endpoints src/core/endpoints.yml",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": []
        },
        {
            "label": "Rasa: Dry Run (lang spec)",
            "type": "shell",
            "command": "bash scripts/layer_rasa_lang.sh --dry-run=stdout ${input:langSpec}",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": []
        },
        {
            "label": "Rasa: Train (lang spec)",
            "type": "shell",
            "command": "bash scripts/layer_rasa_lang.sh ${input:langSpec}",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": []
        },
        {
            "label": "Rasa: Train Hybrid Model (LLM + NLU)",
            "type": "shell",
            "command": "OVERLAY_BASE_CONFIG=\"src/config/hybrid_pipeline_config.yml\" bash scripts/layer_rasa_lang.sh en/US",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": true,
                "clear": false
            }
        },
        {
            "label": "LLM: Manage Models (Interactive)",
            "type": "shell",
            "command": "python scripts/manage_llm_models.py",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": true,
                "panel": "new",
                "showReuseMessage": false,
                "clear": true
            }
        },
        {
            "label": "LLM: Show Current Configuration",
            "type": "shell",
            "command": "python scripts/manage_llm_models.py config",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: List Available Models",
            "type": "shell",
            "command": "python scripts/manage_llm_models.py list",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Change Model",
            "type": "shell",
            "command": "python scripts/manage_llm_models.py change ${input:llmModel}",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Test Current Model",
            "type": "shell",
            "command": "python scripts/manage_llm_models.py test",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Set Environment Variable",
            "type": "shell",
            "command": "export OLLAMA_MODEL=\"${input:llmModel}\" && echo \"âœ… OLLAMA_MODEL variable set: ${input:llmModel}\" && echo \"ðŸ’¡ This variable is active for this VS Code session\"",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Demo Model Change",
            "type": "shell",
            "command": "python scripts/demo_model_change.py",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Full System Test",
            "type": "shell",
            "command": "python scripts/test_final_llm_config.py",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Quick Switch to llama3.1:8b",
            "type": "shell",
            "command": "python scripts/manage_llm_models.py change llama3.1:8b && echo \"ðŸš€ Model changed to llama3.1:8b\"",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}",
                    "OLLAMA_MODEL": "llama3.1:8b"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Quick Switch to llama3.2:3b",
            "type": "shell",
            "command": "python scripts/manage_llm_models.py change llama3.2:3b && echo \"ðŸš€ Model changed to llama3.2:3b\"",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}",
                    "OLLAMA_MODEL": "llama3.2:3b"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Quick Switch to tinyllama",
            "type": "shell",
            "command": "python scripts/manage_llm_models.py change tinyllama && echo \"ðŸš€ Model changed to tinyllama\"",
            "group": "build",
            "options": {
                "cwd": "${workspaceFolder}",
                "env": {
                    "PYTHONPATH": "${workspaceFolder}",
                    "OLLAMA_MODEL": "tinyllama"
                }
            },
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Change Model and Train",
            "dependsOrder": "sequence",
            "dependsOn": [
                "LLM: Change Model",
                "Rasa: Train Hybrid Model (LLM + NLU)"
            ],
            "group": "build",
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        },
        {
            "label": "LLM: Complete Workflow - Change Model + Test + Train",
            "dependsOrder": "sequence",
            "dependsOn": [
                "LLM: Change Model",
                "LLM: Test Current Model",
                "Rasa: Train Hybrid Model (LLM + NLU)"
            ],
            "group": "build",
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared",
                "showReuseMessage": false,
                "clear": false
            }
        }
    ],
    "inputs": [
        {
            "id": "layersPreset",
            "type": "pickString",
            "description": "Choose a layer set (space-separated paths)",
            "options": [
                "src/core src/locales/en/US",
                "src/core src/locales/en/US src/locales/da src/locales/da/DK"
            ],
            "default": "src/core src/locales/en/US"
        },
        {
            "id": "layersCustom",
            "type": "promptString",
            "description": "Enter space-separated layer paths (e.g., src/core src/locales/en/US src/locales/da src/locales/da/DK)",
            "default": "src/core src/locales/da src/locales/da/DK"
        },
        {
            "id": "langSpec",
            "type": "pickString",
            "description": "Language spec (lang or lang/REGION)",
            "options": [
                "en/US",
                "da/DK",
                "es/ES",
                "es/MX",
                "fr/FR",
                "de/DE"
            ],
            "default": "en/US"
        },
        {
            "id": "llmModel",
            "type": "pickString",
            "description": "Choose LLM model",
            "options": [
                "llama3.1:8b",
                "llama3.2:3b",
                "llama3.2:1b",
                "tinyllama",
                "llama2:7b",
                "codellama:7b",
                "mistral:7b",
                "phi3:mini",
                "qwen2:7b"
            ],
            "default": "llama3.1:8b"
        },
        {
            "id": "customLlmModel",
            "type": "promptString",
            "description": "Enter custom LLM model name (e.g., llama3.2:1b, custom-model:latest)",
            "default": "llama3.1:8b"
        }
    ]
}