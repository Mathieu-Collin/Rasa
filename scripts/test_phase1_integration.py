#!/usr/bin/env python3
"""
Test d'intÃ©gration complÃ¨te: Configuration + Client Ollama
Phase 1 - Validation finale de l'infrastructure LLM
"""

import sys
from pathlib import Path

import yaml

# Ajouter le chemin du client
sys.path.insert(0, "/workspace/scripts")
from test_ollama_client import OllamaClient


def load_config():
    """Charge la configuration Ollama"""
    config_path = Path("/workspace/src/config/ollama_config.yml")
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def test_integration():
    """Test d'intÃ©gration complÃ¨te configuration + client"""

    print("ğŸš€ Test d'intÃ©gration Configuration + Client Ollama")
    print("====================================================")

    # 1. Charger la configuration
    print("\n1ï¸âƒ£ Chargement de la configuration...")
    try:
        config = load_config()
        ollama_config = config["ollama"]
        intents_config = config["intents"]
        hybrid_config = config["hybrid_decision"]
        print("   âœ… Configuration chargÃ©e")
    except Exception as e:
        print(f"   âŒ Erreur de chargement: {e}")
        return False

    # 2. Initialiser le client avec la config
    print("\n2ï¸âƒ£ Initialisation du client avec configuration...")
    try:
        client_params = {
            "base_url": ollama_config["base_url"],
            "model": ollama_config["model"],
            "timeout": ollama_config["timeout"],
        }
        client = OllamaClient(**client_params)
        print(f"   âœ… Client initialisÃ©: {client}")
    except Exception as e:
        print(f"   âŒ Erreur d'initialisation: {e}")
        return False

    # 3. Test de santÃ©
    print("\n3ï¸âƒ£ Test de santÃ© du service...")
    if client.health_check():
        print("   âœ… Service Ollama accessible")
    else:
        print("   âŒ Service Ollama inaccessible")
        return False

    # 4. Test du prompt configurÃ©
    print("\n4ï¸âƒ£ Test du prompt configurÃ©...")
    try:
        intent_classification = ollama_config["intent_classification"]
        prompt_template = intent_classification["prompt_template"]
        available_intents = intents_config["supported_intents"]

        test_message = "Hello, how are you today?"
        formatted_prompt = prompt_template.format(
            available_intents=", ".join(available_intents), user_message=test_message
        )

        print(f"   âœ… Prompt formatÃ© ({len(formatted_prompt)} caractÃ¨res)")

        # Test du prompt avec le client
        classification_params = intent_classification.get("classification_params", {})
        response = client.send_prompt(formatted_prompt, **classification_params)
        print(f"   âœ… RÃ©ponse LLM reÃ§ue: {response[:100]}...")

    except Exception as e:
        print(f"   âŒ Erreur de test du prompt: {e}")
        return False

    # 5. Test de classification avec les intentions configurÃ©es
    print("\n5ï¸âƒ£ Test de classification avec intentions configurÃ©es...")
    try:
        available_intents = intents_config["supported_intents"]
        test_messages = [
            ("Hello, how are you?", "greet"),
            ("Goodbye, see you later!", "goodbye"),
            ("What time is it?", "question"),
            ("Show me the dashboard", "command"),
            ("blah blah unclear message", "fallback"),
        ]

        correct_predictions = 0
        total_predictions = len(test_messages)

        for message, expected_intent in test_messages:
            try:
                predicted_intent, confidence = client.classify_intent(
                    message, available_intents, temperature=0.1
                )

                is_correct = predicted_intent == expected_intent
                correct_predictions += is_correct

                status = "âœ…" if is_correct else "âš ï¸"
                print(
                    f"   {status} '{message}' -> {predicted_intent} (attendu: {expected_intent}, conf: {confidence:.2f})"
                )

            except Exception as e:
                print(f"   âŒ Erreur pour '{message}': {e}")

        accuracy = correct_predictions / total_predictions * 100
        print(
            f"   ğŸ“Š PrÃ©cision: {accuracy:.1f}% ({correct_predictions}/{total_predictions})"
        )

        if accuracy >= 60:  # Seuil acceptable pour un modÃ¨le 1B
            print("   âœ… PrÃ©cision acceptable")
        else:
            print("   âš ï¸  PrÃ©cision faible")

    except Exception as e:
        print(f"   âŒ Erreur de test de classification: {e}")
        return False

    # 6. Test des seuils de dÃ©cision
    print("\n6ï¸âƒ£ Validation des seuils de dÃ©cision...")
    try:
        nlu_threshold = hybrid_config["nlu_priority_threshold"]
        llm_threshold = hybrid_config["llm_priority_threshold"]
        agreement_threshold = hybrid_config["agreement_threshold"]

        print(f"   âœ… Seuil prioritÃ© NLU: {nlu_threshold}")
        print(f"   âœ… Seuil prioritÃ© LLM: {llm_threshold}")
        print(f"   âœ… Seuil d'accord: {agreement_threshold}")

        # Test de la logique de dÃ©cision
        if nlu_threshold < llm_threshold:
            print("   âœ… Logique de seuils cohÃ©rente")
        else:
            print("   âš ï¸  Seuils incohÃ©rents (NLU devrait Ãªtre < LLM)")

    except Exception as e:
        print(f"   âŒ Erreur de validation des seuils: {e}")
        return False

    # 7. Statistiques finales
    print("\n7ï¸âƒ£ Statistiques du client...")
    stats = client.get_stats()
    print(f"   ğŸ“Š Total requÃªtes: {stats['total_requests']}")
    print(f"   ğŸ“Š RequÃªtes rÃ©ussies: {stats['successful_requests']}")
    print(f"   ğŸ“Š Temps moyen: {stats['avg_response_time']:.2f}s")

    success_rate = (
        (stats["successful_requests"] / stats["total_requests"] * 100)
        if stats["total_requests"] > 0
        else 0
    )
    print(f"   ğŸ“Š Taux de succÃ¨s: {success_rate:.1f}%")

    # CritÃ¨res de validation finale
    criteria_met = [
        success_rate >= 90,  # Au moins 90% de succÃ¨s
        stats["avg_response_time"] < 3.0,  # Temps moyen < 3s
        accuracy >= 50,  # PrÃ©cision >= 50% (tolÃ©rant pour modÃ¨le 1B)
    ]

    print("\nğŸ“‹ CritÃ¨res de validation:")
    print(
        f"   {'âœ…' if criteria_met[0] else 'âŒ'} Taux de succÃ¨s >= 90%: {success_rate:.1f}%"
    )
    print(
        f"   {'âœ…' if criteria_met[1] else 'âŒ'} Temps moyen < 3s: {stats['avg_response_time']:.2f}s"
    )
    print(f"   {'âœ…' if criteria_met[2] else 'âŒ'} PrÃ©cision >= 50%: {accuracy:.1f}%")

    all_criteria_met = all(criteria_met)

    if all_criteria_met:
        print("\nğŸ‰ PHASE 1 VALIDÃ‰E - Infrastructure LLM Ollama opÃ©rationnelle !")
        print("ğŸš€ PrÃªt pour la Phase 2: DÃ©veloppement du LLM Intent Router")
        return True
    else:
        print("\nâš ï¸  Certains critÃ¨res non atteints - Optimisation requise")
        return False


if __name__ == "__main__":
    success = test_integration()
    exit(0 if success else 1)
