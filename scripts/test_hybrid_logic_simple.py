#!/usr/bin/env python3
"""
Test simple de la logique LLM Intent Router
Version simplifiee sans mocks complexes
"""

import sys

sys.path.insert(0, "/workspace/scripts")
sys.path.insert(0, "/workspace")


def hybrid_classify_logic(nlu_confidence, llm_confidence, nlu_intent, llm_intent):
    """
    Logique hybride de classification d'intentions - fonction export√©e

    Args:
        nlu_confidence: Confidence du NLU RASA (0.0-1.0)
        llm_confidence: Confidence du LLM Ollama (0.0-1.0)
        nlu_intent: Intention pr√©dite par le NLU
        llm_intent: Intention pr√©dite par le LLM

    Returns:
        Tuple (intention_finale, confidence_finale, raison_decision)
    """
    # Seuils configurables (normalement depuis config)
    NLU_PRIORITY_THRESHOLD = 0.8
    LLM_PRIORITY_THRESHOLD = 0.9
    AGREEMENT_THRESHOLD = 0.1

    # 1. NLU haute confiance -> priorit√© NLU
    if nlu_confidence >= NLU_PRIORITY_THRESHOLD:
        return (nlu_intent, nlu_confidence, "nlu_high_confidence")

    # 2. LLM haute confiance -> priorit√© LLM
    if llm_confidence >= LLM_PRIORITY_THRESHOLD:
        return (llm_intent, llm_confidence, "llm_high_confidence")

    # 3. Accord entre NLU et LLM -> utiliser le plus confiant
    if nlu_intent == llm_intent:
        if llm_confidence >= nlu_confidence:
            return (llm_intent, llm_confidence, "llm_agreement")
        else:
            return (nlu_intent, nlu_confidence, "nlu_agreement")

    # 4. Confiances proches -> utiliser NLU (plus fiable)
    if abs(nlu_confidence - llm_confidence) <= AGREEMENT_THRESHOLD:
        return (nlu_intent, nlu_confidence, "confidence_proximity")

    # 5. D√©saccord -> utiliser le plus confiant
    if llm_confidence > nlu_confidence:
        return (llm_intent, llm_confidence, "llm_higher_confidence")
    else:
        return (nlu_intent, nlu_confidence, "nlu_higher_confidence")


def test_hybrid_logic_simple():
    """Test simple de la logique de decision hybride"""

    print("üß™ Test simplifi√© LLM Intent Router - Logique hybride")
    print("==================================================")

    # Test des seuils et logique de decision
    def hybrid_classify_logic(
        nlu_confidence,
        llm_confidence,
        nlu_intent,
        llm_intent,
        nlu_threshold=0.8,
        llm_threshold=0.9,
        agreement_threshold=0.1,
    ):
        """Logique pure de classification hybride extraite"""

        # Cas 1: NLU tres confiant
        if nlu_confidence >= nlu_threshold:
            return nlu_intent, nlu_confidence, "nlu_high_confidence"

        # Cas 2: LLM tres confiant et different
        if llm_confidence >= llm_threshold and llm_intent != nlu_intent:
            return llm_intent, llm_confidence, "llm_high_confidence"

        # Cas 3: Accord entre NLU et LLM
        if (
            llm_intent == nlu_intent
            or abs(nlu_confidence - llm_confidence) <= agreement_threshold
        ):
            if llm_confidence > nlu_confidence:
                return llm_intent, llm_confidence, "llm_agreement"
            else:
                return nlu_intent, nlu_confidence, "nlu_agreement"

        # Cas 4: Desaccord, confiance la plus elevee
        else:
            if llm_confidence > nlu_confidence:
                return llm_intent, llm_confidence, "llm_disagreement"
            else:
                return nlu_intent, nlu_confidence, "nlu_disagreement"

    # Cas de test pour la logique
    test_cases = [
        {
            "name": "NLU haute confiance",
            "nlu_confidence": 0.95,
            "llm_confidence": 0.7,
            "nlu_intent": "greet",
            "llm_intent": "question",
            "expected_source": "nlu_high_confidence",
            "expected_intent": "greet",
        },
        {
            "name": "LLM haute confiance, desaccord",
            "nlu_confidence": 0.6,
            "llm_confidence": 0.95,
            "nlu_intent": "greet",
            "llm_intent": "question",
            "expected_source": "llm_high_confidence",
            "expected_intent": "question",
        },
        {
            "name": "Accord NLU/LLM, LLM plus confiant",
            "nlu_confidence": 0.7,
            "llm_confidence": 0.8,
            "nlu_intent": "greet",
            "llm_intent": "greet",
            "expected_source": "llm_agreement",
            "expected_intent": "greet",
        },
        {
            "name": "Accord par proximite confiance",
            "nlu_confidence": 0.75,
            "llm_confidence": 0.8,
            "nlu_intent": "question",
            "llm_intent": "request",
            "expected_source": "llm_agreement",  # Ecart de 0.05 < 0.1
            "expected_intent": "request",
        },
        {
            "name": "Desaccord, NLU plus confiant",
            "nlu_confidence": 0.75,
            "llm_confidence": 0.6,
            "nlu_intent": "greet",
            "llm_intent": "goodbye",
            "expected_source": "nlu_disagreement",
            "expected_intent": "greet",
        },
        {
            "name": "Desaccord, LLM plus confiant",
            "nlu_confidence": 0.6,
            "llm_confidence": 0.75,
            "nlu_intent": "question",
            "llm_intent": "command",
            "expected_source": "llm_disagreement",
            "expected_intent": "command",
        },
    ]

    print("\n1Ô∏è‚É£ Test de la logique de decision hybride...")

    success_count = 0
    total_tests = len(test_cases)

    for i, test in enumerate(test_cases, 1):
        print(f"\n   Test {i}: {test['name']}")
        print(f"      NLU: {test['nlu_intent']} (conf: {test['nlu_confidence']})")
        print(f"      LLM: {test['llm_intent']} (conf: {test['llm_confidence']})")

        try:
            final_intent, final_conf, source = hybrid_classify_logic(
                test["nlu_confidence"],
                test["llm_confidence"],
                test["nlu_intent"],
                test["llm_intent"],
            )

            print(
                f"      R√©sultat: {final_intent} (conf: {final_conf:.2f}, source: {source})"
            )

            # Verification
            intent_correct = final_intent == test["expected_intent"]
            source_correct = source == test["expected_source"]

            if intent_correct and source_correct:
                print("      ‚úÖ Test r√©ussi")
                success_count += 1
            else:
                print("      ‚ùå Test √©chou√©:")
                if not intent_correct:
                    print(
                        f"         Intention attendue: {test['expected_intent']}, obtenue: {final_intent}"
                    )
                if not source_correct:
                    print(
                        f"         Source attendue: {test['expected_source']}, obtenue: {source}"
                    )

        except Exception as e:
            print(f"      ‚ùå Erreur: {e}")

    print(f"\nüìä R√©sultats des tests de logique: {success_count}/{total_tests} r√©ussis")

    # Test des seuils de configuration
    print("\n2Ô∏è‚É£ Test des seuils de configuration...")

    seuil_tests = [
        {
            "name": "Seuils par d√©faut",
            "nlu_threshold": 0.8,
            "llm_threshold": 0.9,
            "agreement_threshold": 0.1,
            "valid": True,
        },
        {
            "name": "Seuils invers√©s (invalide)",
            "nlu_threshold": 0.9,
            "llm_threshold": 0.8,
            "agreement_threshold": 0.1,
            "valid": False,
            "warning": "LLM threshold devrait √™tre >= NLU threshold",
        },
        {
            "name": "Seuil d'accord trop √©lev√©",
            "nlu_threshold": 0.8,
            "llm_threshold": 0.9,
            "agreement_threshold": 0.5,
            "valid": False,
            "warning": "Seuil d'accord trop √©lev√©",
        },
    ]

    config_success = 0
    for i, test in enumerate(seuil_tests, 1):
        print(f"\n   Test config {i}: {test['name']}")
        print(
            f"      NLU: {test['nlu_threshold']}, LLM: {test['llm_threshold']}, Accord: {test['agreement_threshold']}"
        )

        # Validation basique des seuils
        nlu_ok = 0.0 <= test["nlu_threshold"] <= 1.0
        llm_ok = 0.0 <= test["llm_threshold"] <= 1.0
        agreement_ok = 0.0 <= test["agreement_threshold"] <= 1.0
        logic_ok = test["llm_threshold"] >= test["nlu_threshold"]
        reasonable_agreement = test["agreement_threshold"] <= 0.2

        all_valid = (
            nlu_ok and llm_ok and agreement_ok and logic_ok and reasonable_agreement
        )

        if all_valid == test["valid"]:
            print("      ‚úÖ Validation correcte")
            config_success += 1
        else:
            print("      ‚ùå Validation incorrecte")
            if "warning" in test:
                print(f"         Attendu: {test['warning']}")

    print(
        f"\nüìä R√©sultats tests configuration: {config_success}/{len(seuil_tests)} r√©ussis"
    )

    # Test d'integration avec Ollama (si disponible)
    print("\n3Ô∏è‚É£ Test d'int√©gration Ollama...")

    try:
        from test_ollama_client import OllamaClient

        client = OllamaClient()
        if client.health_check():
            print("   ‚úÖ Service Ollama accessible")

            # Test rapide de classification
            test_intent, test_conf = client.classify_intent(
                "Hello how are you today?",
                ["greet", "goodbye", "question", "command", "fallback"],
                temperature=0.1,
            )

            print(f"   ‚úÖ Classification test: '{test_intent}' (conf: {test_conf:.2f})")

            integration_success = True
        else:
            print("   ‚ö†Ô∏è  Service Ollama non accessible")
            integration_success = False

    except Exception as e:
        print(f"   ‚ùå Erreur int√©gration Ollama: {e}")
        integration_success = False

    # Score final
    total_score = (
        (success_count + config_success) / (total_tests + len(seuil_tests)) * 100
    )

    print(f"\nüéØ Score final: {total_score:.1f}%")

    if total_score >= 85:
        print("üéâ LOGIQUE HYBRIDE VALID√âE - Pr√™t pour l'int√©gration RASA !")
        return True
    else:
        print("‚ö†Ô∏è  Logique partiellement valid√©e - Optimisations recommand√©es")
        return False


if __name__ == "__main__":
    success = test_hybrid_logic_simple()
    exit(0 if success else 1)
