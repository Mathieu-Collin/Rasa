"""
LLM Intent Router - Composant hybride pour RASA
Combine les predictions NLU traditionnelles avec un LLM Ollama
Version simplifi√©e sans configuration centralis√©e
"""

import logging
from typing import Any, Dict, List, Optional, Text, Tuple

from rasa.engine.graph import ExecutionContext, GraphComponent
from rasa.engine.recipes.default_recipe import DefaultV1Recipe
from rasa.engine.storage.resource import Resource
from rasa.engine.storage.storage import ModelStorage
from rasa.shared.nlu.training_data.message import Message

# Import du client Ollama
from .ollama_client import OllamaClient

logger = logging.getLogger(__name__)


@DefaultV1Recipe.register(
    DefaultV1Recipe.ComponentType.INTENT_CLASSIFIER, is_trainable=False
)
class LLMIntentRouter(GraphComponent):
    """
    Composant hybride qui combine les classifications NLU RASA avec un LLM Ollama
    pour am√©liorer la precision de detection d'intentions
    """

    def __init__(self, config: Dict[Text, Any]) -> None:
        """Initialise le LLM Intent Router avec configuration simple"""
        self._config = config

        # Configuration Ollama simple
        self.ollama_enabled = config.get("ollama_enabled", True)
        self.ollama_base_url = config.get("ollama_base_url", "http://ollama:11434")
        self.ollama_model = config.get("ollama_model", "llama3.1:8b")
        self.ollama_timeout = config.get("ollama_timeout", 30)

        # Seuils de d√©cision
        self.nlu_priority_threshold = config.get("nlu_priority_threshold", 0.95)
        self.llm_priority_threshold = config.get(
            "llm_priority_threshold", 0.6
        )  # Abaiss√© pour plus de fallback
        self.agreement_threshold = config.get("agreement_threshold", 0.1)
        self.tie_breaker = config.get("tie_breaker", "llm")

        # Options + NOUVEAUX PARAM√àTRES FALLBACK üö®
        self.fallback_to_nlu = config.get("fallback_to_nlu", True)
        self.fallback_threshold = config.get("fallback_threshold", 0.4)
        self.unknown_intent_threshold = config.get("unknown_intent_threshold", 0.3)
        self.force_fallback_keywords = config.get(
            "force_fallback_keywords",
            ["song", "music", "recipe", "weather", "news", "joke", "story", "poem"],
        )
        self.cache_llm_responses = config.get("cache_llm_responses", True)
        self.debug_logging = config.get("debug_logging", False)

        # Cache pour les r√©ponses LLM
        self._llm_cache = {} if self.cache_llm_responses else None

        # Initialisation du client Ollama
        if self.ollama_enabled:
            try:
                self.ollama_client = OllamaClient(
                    base_url=self.ollama_base_url,
                    model=self.ollama_model,
                    timeout=self.ollama_timeout,
                )
                logger.info("LLM Intent Router initialise avec Ollama actif")
            except Exception as e:
                logger.error(f"Erreur initialisation Ollama: {e}")
                self.ollama_enabled = False
                self.ollama_client = None
        else:
            self.ollama_client = None
            logger.info("LLM Intent Router initialise SANS Ollama")

    @classmethod
    def create(
        cls,
        config: Dict[Text, Any],
        model_storage: ModelStorage,
        resource: Resource,
        execution_context: ExecutionContext,
    ) -> "LLMIntentRouter":
        """M√©thode de cr√©ation requise par RASA"""
        return cls(config)

    def process(self, messages: List[Message]) -> List[Message]:
        """
        Traite les messages et applique la logique hybride NLU + LLM
        """
        for message in messages:
            self._process_single_message(message)
        return messages

    def _process_single_message(self, message: Message) -> None:
        """Traite un message unique avec la logique hybride"""
        try:
            # R√©cup√©rer le texte du message
            text = message.get("text", "")

            # üö® D√âTECTION PR√âCOCE DE FALLBACK par mots-cl√©s
            if self._should_force_fallback(text):
                if self.debug_logging:
                    logger.info(f"    üö® FALLBACK FORC√â par mots-cl√©s: '{text}'")
                message.set(
                    "intent",
                    {"name": "fallback", "confidence": 0.8},
                    add_to_output=True,
                )
                return

            # R√©cup√©rer la pr√©diction NLU existante (peut √™tre vide en premi√®re position)
            nlu_intent = message.get("intent", {})
            nlu_intent_name = nlu_intent.get("name") if nlu_intent else None
            nlu_confidence = nlu_intent.get("confidence", 0.0) if nlu_intent else 0.0

            # R√©cup√©rer les intentions disponibles
            available_intents = self._get_available_intents()

            # Appliquer la logique de d√©cision hybride
            final_intent, final_confidence, decision_source = self._hybrid_decision(
                text,
                nlu_intent_name,
                nlu_confidence,
                available_intents,
            )

            # Mettre √† jour le message si n√©cessaire
            if final_intent is not None and (
                final_intent != nlu_intent_name or final_confidence != nlu_confidence
            ):
                message.set(
                    "intent",
                    {"name": final_intent, "confidence": final_confidence},
                    add_to_output=True,
                )

                # Log debug si activ√©
                if self.debug_logging:
                    if nlu_intent_name is not None:
                        logger.info(
                            f"üéØ OVERRIDE LLM: {nlu_intent_name} ‚Üí {final_intent} "
                            f"(source: {decision_source})"
                        )
                    else:
                        logger.info(
                            f"üéØ G√âN√âRATION LLM: {final_intent} "
                            f"(source: {decision_source})"
                        )
            elif final_intent is None and self.debug_logging:
                logger.info("‚è≠Ô∏è Pas d'intervention LLM: laisser pipeline continuer")

        except Exception as e:
            logger.error(f"Erreur traitement message: {e}")
            # En cas d'erreur, on garde le r√©sultat NLU original ou on laisse passer

    def _hybrid_decision(
        self,
        text: str,
        nlu_intent: Optional[str],
        nlu_confidence: float,
        available_intents: List[str],
    ) -> Tuple[Optional[str], float, str]:
        """
        Logique de d√©cision hybride entre NLU et LLM
        Retourne: (intent_final, confidence_finale, source_decision)

        G√®re deux cas :
        1. Position APR√àS DIETClassifier : nlu_intent existe ‚Üí logique hybride
        2. Position AVANT DIETClassifier : nlu_intent=None ‚Üí LLM g√©n√®re intention initiale
        """

        # CAS SP√âCIAL: Premi√®re position dans le pipeline - Pas d'intention NLU
        if nlu_intent is None:
            if self.debug_logging:
                logger.info("    üöÄ Position initiale: g√©n√©ration intention par LLM")

            if not self.ollama_enabled or not self.ollama_client:
                # Pas de LLM disponible en premi√®re position ‚Üí laisser passer au DIETClassifier
                if self.debug_logging:
                    logger.info(
                        "    ‚è≠Ô∏è Ollama indisponible, laisser DIETClassifier d√©cider"
                    )
                return None, 0.0, "skip_to_diet_classifier"

            # Obtenir pr√©diction LLM pour intention initiale
            try:
                llm_intent, llm_confidence = self._get_llm_prediction(
                    text, available_intents
                )

                if (
                    llm_intent
                    and llm_confidence
                    and llm_confidence >= self.llm_priority_threshold
                ):
                    if self.debug_logging:
                        logger.info(
                            f"    üéØ LLM g√©n√®re intention initiale: {llm_intent} ({llm_confidence:.3f})"
                        )
                    return llm_intent, llm_confidence, "llm_initial_generation"
                else:
                    # LLM pas assez confiant ‚Üí laisser DIETClassifier d√©cider
                    confidence_str = (
                        f"{llm_confidence:.3f}" if llm_confidence else "None"
                    )
                    if self.debug_logging:
                        logger.info(
                            f"    ‚è≠Ô∏è LLM pas confiant ({confidence_str}), laisser DIETClassifier"
                        )
                    return None, 0.0, "skip_to_diet_classifier"

            except Exception as e:
                logger.error(f"Erreur LLM en position initiale: {e}")
                return None, 0.0, "skip_to_diet_classifier"

        # CAS NORMAL: Position APR√àS DIETClassifier - Analyse de l'intention NLU
        if nlu_confidence >= self.nlu_priority_threshold:
            if self.debug_logging:
                logger.info(
                    f"    ‚úÖ NLU tr√®s confiant ({nlu_confidence:.3f} >= {self.nlu_priority_threshold}) - Pas de consultation LLM"
                )
            return nlu_intent, nlu_confidence, "nlu_very_high_confidence"

        # CAS HYBRIDE: NLU pas assez confiant - Consultation LLM pour am√©lioration
        if not self.ollama_enabled or not self.ollama_client:
            if self.debug_logging:
                logger.info("    ‚ùå Ollama d√©sactiv√©, fallback vers pr√©diction NLU")
            return nlu_intent, nlu_confidence, "nlu_fallback"
            return nlu_intent, nlu_confidence, "ollama_disabled"

        # Obtenir pr√©diction LLM
        try:
            llm_intent, llm_confidence = self._get_llm_prediction(
                text, available_intents
            )

            if self.debug_logging:
                logger.info("üéØ HYBRID CLASSIFICATION DEBUG")
                logger.info(f"    üìù Texte: '{text}'")
                logger.info(
                    f"    ÔøΩ NLU Pr√©diction: {nlu_intent} ({nlu_confidence:.3f})"
                )
                logger.info(
                    f"    ü§ñ LLM Pr√©diction: {llm_intent} ({llm_confidence:.3f})"
                )

            if llm_intent is None or llm_confidence is None:
                # LLM failed
                return nlu_intent, nlu_confidence, "llm_failed"

            # Logique de d√©cision selon les seuils
            return self._decide_between_nlu_and_llm(
                nlu_intent, nlu_confidence, llm_intent, llm_confidence
            )

        except Exception as e:
            logger.error(f"Erreur consultation LLM: {e}")
            return nlu_intent, nlu_confidence, "llm_error"

    def _get_llm_prediction(
        self, text: str, available_intents: List[str]
    ) -> Tuple[Optional[str], Optional[float]]:
        """Obtient une pr√©diction du LLM Ollama"""
        try:
            # V√©rifier le cache d'abord
            if self._llm_cache and text in self._llm_cache:
                return self._llm_cache[text]

            # Appeler Ollama
            intent, confidence = self.ollama_client.classify_intent(
                text, available_intents
            )

            # Mettre en cache le r√©sultat
            if self._llm_cache and intent is not None:
                self._llm_cache[text] = (intent, confidence)

            return intent, confidence

        except Exception as e:
            logger.error(f"Erreur pr√©diction LLM: {e}")
            return None, None

    def _decide_between_nlu_and_llm(
        self,
        nlu_intent: str,
        nlu_confidence: float,
        llm_intent: str,
        llm_confidence: float,
    ) -> Tuple[str, float, str]:
        """D√©cide entre NLU et LLM selon la logique hybride avec fallback intelligent"""

        # üö® FALLBACK INTELLIGENT AM√âLIOR√â: Si les deux mod√®les sont peu confiants
        if (
            nlu_confidence < self.fallback_threshold
            and llm_confidence < self.fallback_threshold
        ):
            if self.debug_logging:
                logger.info(
                    f"    üö® FALLBACK INTELLIGENT: NLU={nlu_confidence:.3f} et LLM={llm_confidence:.3f} < {self.fallback_threshold}"
                )
            return (
                "fallback",
                0.9,
                "intelligent_fallback",
            )  # Confiance √©lev√©e pour le fallback

        # üö® NOUVEAU: D√©tection LLM d'intention inconnue
        if llm_intent == "fallback" and llm_confidence >= self.unknown_intent_threshold:
            if self.debug_logging:
                logger.info(
                    f"    üö® LLM D√âTECTE DEMANDE HORS SCOPE: LLM confidence={llm_confidence:.3f}"
                )
            return "fallback", 0.85, "llm_detected_unknown"

        # CAS 3: LLM confiant
        if llm_confidence >= self.llm_priority_threshold:
            # CAS 3a: Accord entre NLU et LLM
            if nlu_intent == llm_intent:
                # Moyenne pond√©r√©e pour renforcer la confiance
                final_confidence = (nlu_confidence + llm_confidence) / 2
                decision = "nlu_llm_agreement"
            else:
                # CAS 3b: D√©saccord - LLM gagne si strat√©gie LLM prioritaire
                if self.tie_breaker == "llm":
                    decision = "llm_confident"
                    # Boost confiance pour √©viter FallbackClassifier override
                    boosted_confidence = max(llm_confidence, 0.85)
                    return llm_intent, boosted_confidence, decision
                else:
                    decision = "nlu_confident"
                    return nlu_intent, nlu_confidence, decision

            return llm_intent, final_confidence, decision

        # CAS 4: LLM pas confiant
        else:
            # Accord malgr√© faible confiance LLM
            if nlu_intent == llm_intent:
                # Utiliser la confiance la plus √©lev√©e
                if nlu_confidence >= llm_confidence:
                    return nlu_intent, nlu_confidence, "nlu_llm_weak_agreement"
                else:
                    return llm_intent, llm_confidence, "nlu_llm_weak_agreement"
            else:
                # D√©saccord + LLM pas confiant - NLU gagne
                return nlu_intent, nlu_confidence, "nlu_default"

    def _get_available_intents(self) -> List[str]:
        """R√©cup√®re la liste des intentions disponibles"""
        # Intents par d√©faut - peut √™tre √©tendu si n√©cessaire
        default_intents = [
            "greet",
            "goodbye",
            "affirm",
            "deny",
            "mood_great",
            "mood_unhappy",
            "generate_visualization",
            "chitchat",
            "fallback",
        ]
        return default_intents

    def _should_force_fallback(self, text: str) -> bool:
        """
        D√©termine si le texte contient des mots-cl√©s qui forcent un fallback
        üö® Nouveau: D√©tection des demandes hors scope du chatbot m√©dical
        """
        if not text:
            return False

        text_lower = text.lower()

        # V√©rifier les mots-cl√©s de fallback configur√©s
        for keyword in self.force_fallback_keywords:
            if keyword.lower() in text_lower:
                return True

        # D√©tection de patterns hors scope m√©dical
        out_of_scope_patterns = [
            "forget everything",
            "ignore instructions",
            "tell me a",
            "sing me",
            "play music",
            "what's the weather",
            "give me a recipe",
            "tell me a joke",
        ]

        for pattern in out_of_scope_patterns:
            if pattern.lower() in text_lower:
                return True

        return False
